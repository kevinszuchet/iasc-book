<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>IASC Book</title>

    <!-- Bootstrap CSS CDN -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css" integrity="sha384-9gVQ4dYFwwWSjIDZnLEWnxCjeSWFphJiwGPXr1jddIhOegiu1FwO5qRGvFXOdJZ4" crossorigin="anonymous">
    <!-- Our Custom CSS -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700">
    <link rel="stylesheet" href="/iasc-book/css/style.css">
    <link rel="stylesheet" href="/iasc-book/css/blockquote.css">
    <link rel="stylesheet" href="/iasc-book/css/syntax.css">

    <!-- Font Awesome JS -->
    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/solid.js" integrity="sha384-tzzSw1/Vo+0N5UhStP3bvwWPq+uvzCMfrN1fEFe+xBmv1C/AtVX5K0uZtmcHitFZ" crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/fontawesome.js" integrity="sha384-6OIrr52G08NpOFSZdxxz1xdNSndlD4vdcf/q2myIUVO0VsqaGHJsB0RaBE01VTOY" crossorigin="anonymous"></script>

</head>

<body>

<div class="wrapper">

    <!-- Sidebar Holder -->
<nav class="sidebar">
    <div class="sidebar-header">
        <a href="/iasc-book">
            <h3 class="title">IASC Notes</h3>
        </a>
    </div>

    <ul class="list-unstyled components">
        <p>Temas</p>
        <li>
            <a href="/iasc-book/introduccion">Intro</a>
        </li>
        <li>
            <a href="/iasc-book/cps">CPS</a>
        </li>
        <li>
            <a href="/iasc-book/coroutines">Corrutinas</a>
        </li>
        <li>
            <a href="#actoresSubmenu" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Actores</a>
            <ul class="collapse list-unstyled" id="actoresSubmenu">
                <li>
                    <a href="/iasc-book/actores_intro">Introduccion Actores</a>
                </li>
                <li>
                    <a href="/iasc-book/otp">Elixir OTP</a>
                </li>
            </ul>
        </li>
        <li>
            <a href="#stmSubmenu" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Memoria
                Transaccional</a>
            <ul class="collapse list-unstyled" id="stmSubmenu">
                <li>
                    <a href="/iasc-book/efecto_lado_haskell">Efectos de lado en Haskell</a>
                </li>
                <li>
                    <a href="/iasc-book/stm">STM</a>
                </li>
            </ul>
        </li>
        <li>
            <a href="#distriSubmenu" data-toggle="collapse" aria-expanded="false"
               class="dropdown-toggle">Distribucion</a>
            <ul class="collapse list-unstyled" id="distriSubmenu">
                <li>
                    <a href="/iasc-book/distribucion">Introduccion a distribucion</a>
                </li>
                <li>
                    <a href="/iasc-book/cap">Notas sobre CAP</a>
                </li>
            </ul>
        </li>
    </ul>

    <div class="sidebar-header">
        <form action="/iasc-book/search" method="get">
            <input type="text" class="search-leftbar" id="search_box" name="query">
            <input type="submit" value="Buscar">
        </form>
    </div>
</nav>

    <div class="container header">
        <nav class="navbar navbar-expand-lg navbar-light">
    <button type="button" id="sidebarCollapse" class="btn btn-info">
        <i class="fa fa-align-justify"></i> <span>toggle sidebar</span>
    </button>
    <!--<a class="navbar-brand" href="#">Navbar</a> -->
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
        <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
                <a class="nav-link" href="/iasc-book">Home <span class="sr-only">(current)</span></a>
            </li>
            <li class="nav-item">
                <a class="nav-link navbar-button" href="http://arquitecturas-concurrentes.github.io/">IASC</a>
            </li>
        </ul>
    </div>
</nav>


        <div class="titulo-heading">
    <div class="container-background">
        <div class="titulo">
            <h3 class="Title">
                Busqueda dentro del sitio
            </h3>
            <br>
            <h4>
                
            </h4>
        </div>
    </div>
</div>

        <div class="container">

            <div class="inner-content col-sm-8 col-md-10">
                <div class="search">
    <form action="/iasc-book/search" method="get">
  <label for="search-box">Ingresa alguna palabra clave</label>
  <input type="text" id="search-box" name="query" />
  <input type="submit" value="buscar" />
</form>

<div class="search-results">
    <h3>Search Results</h3>
    <ul id="search-results"></ul>
</div>

<script>
  window.store = {
    
      "actores-intro": {
        "title": "Capitulo 7 - Actores",
        "content": "IntroduccionEl modelo de Actores, como vimos, tiene muchas similitudes al paradigma de objetos aunque con algunas diferencias. El modelo de actores en si se define como uno que puede lidiar con computaciones concurrentes, por lo que hay algunas reglas en cómo deben ser modelados estos componentes, su comportamiento e interacción. El modelo de actores tiene su unidad de computación más primitiva que es un actor, y que es una computación que recibe un mensaje y hace un procesamiento en base a eso, tambien ademas de recibir mensajes, puede enviar mensajes, tiene una identidad, que es mediante un id único en el sistema. Si empezamos a ver que un actor posee identidad, y envío/recepción de mensajes, uno pensaría que es bastante similar a la de un objeto, o no?. Bueno también un actor, cuando recibe un mensaje, hace algo dependiendo del mensaje que recibe ( similar a cuando llamamos a un método determinado a un objeto). Existen diferencias entre actores y objetos, y la más notoria es que en un modelo de objetos, varios objetos se ejecutan en una unidad de procesamiento (proceso o thread) y comparten recursos como memoria, esto no es lo mismo en el paradigma de actores en el que los actores son en realidad un contexto de ejecución y están completamente aislados uno de otros y nunca van a compartir memorias u otros recursos. También se debe aclarar que un actor puede mantener un estado privado y que este no puede ser cambiado directamente por otro actor (encapsulamiento). En el modelo de actores, nuestro sistema tiene que estar diagramado en actores y todo es un actor, y tienen que tener direcciones siempre, y esta dirección es lo que hablábamos antes que era el identificador en el ecosistema.Los Actores además tienen un mailbox (buzón), en donde van a poder recibir los mensajes de otros actores, y por qué es esto? Bueno porque el envío de mensajes entre actores es asincrónico, por lo cual nunca se sabe exactamente cuando un actor recibe un mensaje, y el modelo elige este modelo de envío de mensajes, ya que al ser una unidad de ejecucion tambien, si se hacen llamadas sincrónicas, el proceso se quedara esperando a una respuesta que puede tal vez nunca llegar o demorar mucho más tiempo, quedando este proceso bloqueado mientras tanto y no dejando de que se pueda ejecutar otro actor que tal vez puede procesar algo. Al poder un actor recibir más de un mensaje en poco tiempo, y al procesar estos de a uno, si se recibe otro mensaje, el actor no lo puede recibir y procesar inmediatamente, por lo que estos mensajes que por el momento el actor no puede procesar quedan encolados en el buzón.También estos escenarios suceden al tener múltiples actores que pueden ejecutarse al mismo tiempo, aunque un actor puede procesar un mensaje al mismo tiempo por lo que de nuevo, si un actor recibe al mismo tiempo 3 mensajes, va a ejecutar uno solo a la vez y por lo tanto hay que mantener un estado de que después hay dos mensajes más por ser procesados, esta es la razón de que los actores tengan un buzón. Si queremos que se ejecuten concurrentemente 3 mensajes, deberemos tener 3 actores y que se le envie un mensaje a cada uno.Que pueden hacer los actores  Enviar y procesar mensajes de otros actores  Crear mas actores  ejecutar otro código después de procesar un mensaje.Mencionamos que los actores son también una abstracción que tiene un contexto de ejecución propio, quien se encarga entonces de ejecutar a los actores. En la VM de Erlang/Elixir, existe algo llamado Scheduler, que se encarga de la coordinación de los actores y de la ejecución sobre un procesador del actor. Mas sobre el scheduler de BEAMQue pasa cuando un actor no tiene ningun mensaje mas para procesar? El mismo muere. El ciclo de vida de un actor es relativamente corto y está pensado para que realice una acción en particular, reciba, envíe mensajes y cree otros actores, pero cuando deja de tener acciones futuras a realizar el mismo muere. Cómo podemos evitar que esto suceda? Bueno si queremos que un actor pueda quedar vivo, esperando a que reciba un mensaje eventualmente, podemos tan solo hacer eso llamándose a sí mismo y haciendo eso. Podemos ver un ejemplo aquíOtro tema importante es que un actor no tiene métodos como los objetos, y el comportamiento de esta última está provista por las clases siempre. En Elixir/Erlang, existe algo más o menos similar que son los módulos, que podemos definir funciones que podemos pasarlas al actor para que las ejecute, es importante la siguiente línea del ejemplo anteriorspawn(fn -&gt; loop end)Spawn es la primitiva para crear un actor, y se le puede pasar una función que sea un loop que se llame a sí mismo y de acuerdo al mensaje que reciba realizará una acción. Esta es la manera más simple de que un actor quede vivo después de procesar los mensajes que tiene en el mailbox.Hay otra librería que nos ayuda mucho a no tener que preocuparnos por esto que es OTP, que nos va a ayudar a modelar, mediante módulos que son más bien recurrentes, diferente tipos de actores que harán distintas acciones puntuales que nos van a ayudar bastante a que nos centremos más en el dominio de nuestra aplicación.Que pasa si un actor falla por alguna razón? Bueno el mismo muere y hay que volver a crearlo y si recibió un mensaje en particular hay que enviarselo de nuevo, hay maneras de que podamos evitar esto mediante catcheo de excepciones, aunque puede ser a veces que pueda morir por otras razones, con lo cual a veces es mejor dejar de morir un actor solo… Entonces que hago para poder volver a levantar un actor que se murió sin que tenga que hacerlo uno a mano? Hay un módulo de OTP que veremos en la próxima sección que nos ayuda con este tema y son los supervisores.Más info sobre errores en el ecosistema de Erlang/Elixir aquiAdicional:Leer principalmente la primera parte que describe brevemente el paradigma de actores junto con actores en Erlang y el scheduling en Erlang.https://rocketeer.be/articles/concurrency-in-erlang-scala/",
        "url": "/iasc-book/actores_intro/"
      }
      ,
    
      "cap": {
        "title": "CAP",
        "content": "CAPHay alguna manera de que manteniendo la aplicación disponible durante intearleaves no haya pérdida de datos? La respuesta rápida es no. No hay manera que la aplicación funcione correctamente en un interleave. esta idea es conocida como el teorema CAPCAP es Consistency, Avaliability, Partition ToleranceConsistencia: Esta es la habilidad que nuestra sistema, tenga 2 o 312123243 nodos que pueda responder a consultas y que tenga el mismo estado, no importa al nodo al que se la hace la consulta. Esto es algo que se logra con transacciones o un mecanismo equivalente. Entonces se tiene que poder ver a todos los nodos como un bloque indivisible. Esto es lo que vimos al comienzo con los contadores, que siempre quede en un estado conocido para el sistema y que no haya por ej. dos nodos que respondan algo distinto al mismo tiempo de realizar la consulta.Disponibilidad: Es simple que siempre que se le pida al sistema por algo de información el sistema me responda, y si no lo hace no está disponible.Particionamiento: Esta parte del teorema es un poco más capciosa. Tolerancia a las particiones significa que el sistema puede seguir funcionando (y contener información útil, estado) aún cuando las partes no puedan comunicarse entre sí. Todo el punto de la tolerancia a la partición es que ese sistema pueda trabajar con mensajes que estén posiblemente perdidos entre componentes. Esto es algo abstracto pero iremos explicando más de esto.CAP Clasico o TradicionalLa interpretación que veremos ahora es la clásica en la que solo se puede tener dos de los tres conceptos de CAP, es decir se puede tener CA, CP o AP. No hay manera de que se puedan tener los tres. Lo malo es que no es posible tener las tres cosas incluso con un fallo de red. Lo bueno es que es un teorema, después veremos que esto es más abierto en la interpretación gradual.  tener Consistencia y Disponibilidad no es posible a menos que teóricamente no falle nunca la red, y si sucede en un nodo todo debería fallar. Entonces nos quedan las otras dos partes. AP o CP. Cuando hay un netsplit o interleave la disponibilidad o consistencia permanecen, pero no ambas.El esquema que toman ambas opciones son las siguientes:CP: El estado no cambio, no hay nada que hacerAP: Tiene más flexibilidad y problemas que resolver, se utilizan distintas estrategias:  La última escritura gana, es una resolución del conflicto en donde cualquiera que haga la última escritura, es el valor del estado que queda.  Esto puede ser algo abierto ya que en sistemas distribuidos, los timestamps generados pueden ser en el mismo momento o no estarlo incluso presente en el sistema.  Se puede elegir al ganador de la escritura aleatoriamente  Métodos más sofisticados ayudan a reducir los conflictos por medio de timestamps como el primer caso pero con relojes relativos. Los relojes relativos trabajan incrementalmente con un valor que se suma a cada escritura. Lamport Clocks extiende más esta idea  El que almacena el estado, si es un nodo central u otro sistema debe elegir cual de los estados es el correcto, un poco lo que sucede con git cuando tenemos un conflicto.BBDD y CAPEste es el gráfico que vimos en clase sobre CAP y BBDD, el post en el que se detalla más el siguiente:  http://blog.nahurst.com/visual-guide-to-nosql-systemsCap GradualEl otro concepto, un poco más gradual hace hincapié en que hoy por hoy no se puede solo tener dos de estos conceptos que permiten simplificar estos conceptos ya separados, y no hay que elegir entre uno u otro de los otros conceptos aparte de particiones, hablamos de consistencia y disponibilidad, sino que hay un rango de flexibilidad para manejar y recuperarse de las particiones.Mas Sobre CAPLa manera más fácil de entender CAP es pensar que dos nodos separados de una partición, permitiendo que al menos de estos nodos se actualice, permite que el otro se vuelva inconsistente, entonces se deja de lado C.  De la misma manera si se preserva la consistencia, un lado de la partición debe actuar como no disponible, dejando de lado A. Solo cuando se comunican los nodos es posible de preservar tanto C como A, dejando de la P. Entonces siempre se piensa en que se debe elegir dos de tres opciones, por el momento centrémonos en el caso en el que se necesiten realizar particiones, aunque dependendiendo del sistema, no siempre aparecen o se necesitan particiones. Entonces la elección entre C y A puede ocurrir varias veces en el sistema con una granularidad bastante fina, y no siempre es algo consistente en todo el sistema, pueden haber sistemas que prioricen una opción sobre otra. La disponibilidad es continuo entre 0 y 100 porciento, pero puede existir niveles de consistencia.En el caso de la interpretación clásica de CAP, no se considera la latencia y se lo ignora, aunque en práctica, la latencia y las particiones están relacionadas en gran medida. La esencia de CAP toma parte durante un timeout, un período en el que programa debe tomar una decisión sobre la partición:  Cancelar la operación y disminuir la disponibilidad  Continuar con la operación y arriesgar a que aparezcan inconsistenciasEntonces si queremos volver a intentar comunicarnos con el otro nodo, para querer mantener la consistencia, solo demora la decisión si no responde, entonces se puede decir que una partición es algo atado al tiempo en una comunicación. Si no se puede mantener la consistencia con las implicaciones de tiempo en la conexión implican una operación entre C o A. A veces tan solo se puede sacrificar C en pos de tener mayor A o viceversa, y de acuerdo a la partición y el momento y el escenario en el que está el sistema, priorizar una u otra. Por ejemplo, PNUTS de Yahoo incurre en la inconsistencia manteniendo copias remotas asincrónicamente. Sin embargo, hace una copia local maestra, que decrementa la latencia. Esta estrategia trabaja bien en práctica porque los datos de un usuario simple es naturalmente particionado de acuerdo a la localización del usuario. Facebook, usa otra estrategia,  que es la de tener la copia maestra en un lugar, y un usuario remoto en realidad tendría una copia stale más cercana a esta copia maestra. Sin embargo, cuando los usuarios actualizan su página, la actualización va a la copia maestra directamente y los usuarios leerán de esta copia maestra en poco tiempo, a los 20-30 segundos los usuarios empiezan a tener una idea más cercana de lo que está en la copia maestra.Entonces si tenemos particiones, tiene sentido elegir entre A y C? Elegir entre C y A existiendo particiones significa que la probabilidad de particiones puede existir y en caso de falla, fallen múltiples componentes simultáneamente. En realidad lo que sucede es que el sistema realmente pierde algo tanto de C como de A, entonces las tres propiedades en cierta manera son importantes. Hay veces en las que se tiene un sistema en un solo datacenter ( en un solo lugar) y como no poseen particiones, tales diseños incluyendo las RBDMS tradicionales, no necesitan considerar P y son en general AC en su totalidad, estos sistemas en cambio no se particionan sino que optan por el esquema de replicación.Manejando particionesEn el caso en el que se deban manejar las particiones, estas solo dependen del tiempo en el que se generan y luego se debe unificar estas cuando se restauran, entonces una partición se ve como en la siguiente imagen:y hay tres momentos en una partición  El momento en el que comienza una partición  Entrar en una partición explícitamente, que puede limitar algunas operaciones  Inicial la recuperación de una partición cuando se necesita unificar las particiones de un sistema.El último paso apunta a restaurar la consistencia y arreglar los cambios y valores inválidos en las invariantes que se generaron cuando el sistema se particiona. La imagen muestra la evolución de una partición. Una operación normal es una secuencia de operaciones atómicas, y, por lo tanto las particiones empiezan entre operaciones. Si tenemos dos nodos que están interconectados y dejan de hablarse durante un tiempo entonces es muy probable que se haya iniciado una partición, en ese caso el primero inicializa este modo, si en realidad existe una partición, entonces el otro nodo también entrará en este modo, pero solo de un lado se admite la partición. En estos casos debe comunicarse esto al otro nodo para que solo quede de un lado. Cuando un sistema entre en modo partición, dos estrategias son posibles. La primera opción es limitar las operaciones reduciendo la disponibilidad y el segundo guardando información extra sobre las operaciones que pueden ser de ayuda en la recuperación de la partición.Entonces en este punto la comunicación se resume entre los nodos y debe volver a reunificarse el estado único del sistema, en este punto se sabe el estado de ambos nodos y sus historias, la historia en realidad es mejor que las invariantes que forman el estado por un tema que se puede determinar mejor cuál sería el estado final a tomar. El diseñador debe resolver dos problemas  Ambos lados deben quedar consistentes  Debe haber una compensación para los errores cometidos durante la fase de partición.En general se hace una especie de merge dependiendo de la estrategia entre los estados, algo similar a lo que se ve en un CVS, pero hay muchos sistemas que no pueden hacer este mergeo de datos por un tema que no es posible, entonces es el caso en el que se reduce las operaciones disponibles en un sistema durante una partición, Google Docs es un caso de este tipo. Otras opciones son las de tomar por medio de algún algoritmo el dato más nuevo y tomar esas invariantes más nuevas como las definitivas en el sistema.Bibliografía adicional de CAP      http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed        Learn you some Erlang for greater good  ",
        "url": "/iasc-book/cap/"
      }
      ,
    
      "coroutines": {
        "title": "Corrutinas (coroutines)",
        "content": "Anteriormente… en Arquitecturas ConcurrentesHasta ahora trabajamos sobre un modelo de concurrencia basado en un event loop. En este esquema, cada evento se procesa completamente antes de pasar a la ejecución del próximo, y todo esto ocurre en un único thread.Una ventaja que esto implica es que cuando una función se está ejecutando, tenemos la seguridad de que no va a ser interrumpida por el planificador hasta que termine, lo cual evita los problemas de concurrencia tradicionales que habíamos visto al usar threads y locks. Y esto lo logramos gracias a que el event loop le provee un orden a la ejecución concurrente; la serializa.Las corrutinas nos permiten lograr algo similar, sin utilizar (necesariamente) un event loop.  Nota al margen: las corrutinas no son nada nuevo. C++, Smalltalk, Erlang y muchos más (¡hasta PHP!) las tienen desde hace mucho. Pero recientemente han conseguido cierta notoriedad en la industria por su uso en lenguajes como Go, Kotlin y Python.¿Qué es una corrutina?Una corrutina es similar a una subrutina tradicional (piensen en las funciones/procedimientos que vieron en Algoritmos), pero con la diferencia de que, mientras que la salida de una subrutina pone fin a su ejecución, una corrutina puede además suspenderse, cediendo el control a otra hasta que se le indique que debe retomar su ejecución.Para entender mejor a qué nos referimos con esto, veamos un ejemplo en Python, uno de los lenguajes que cuenta con soporte para corrutinas.Sin corrutinasimport timedef io():    time.sleep(1)    print('1')    time.sleep(1)    print('2')    time.sleep(1)    print('3')def main(tareas):    for tarea in tareas:        io()if __name__ == '__main__':    tiempo = time.perf_counter()    main(range(3))    tiempo2 = time.perf_counter() - tiempo    print(f'Tiempo total: {tiempo2:0.2f} segundos')Este código imprime:  123123123Tiempo total: 9.01 segundosPodemos ver que cada ciclo de IOs de cada tarea se ejecuta y termina una atrás de la otra. ¿Qué pasa si agregamos corrutinas?Con corrutinasimport timeimport asyncioasync def io():    #Hay un async adelante del def, asi que soy una corrutina :D    await asyncio.sleep(1)    print(1)    await asyncio.sleep(1)    print(2)    await asyncio.sleep(1)    print(3)async def main():    await asyncio.gather(io(), io(), io())if __name__ == '__main__':    tiempo = time.perf_counter()    asyncio.run(main())    tiempo2 = time.perf_counter() - tiempo    print(f'Tiempo total: {tiempo2:0.2f} segundos')  111222333Tiempo total: 3.00 segundosLa diferencia en los tiempos es notable. También observamos que el orden de ejecución fue distinto en este caso.¿Cómo funcionan?Cuando usamos corrutinas, no hay intervención del SO. Hay un sólo proceso, un sólo thread. Entonces… ¿qué es lo que esta pasando?Lo que ocurre es que las corrutinas liberan la CPU cuando están en “tiempo de espera” (await), permitiendo que otras puedan usar la CPU.Podemos decir que es como una simultánea de ajedrez, en donde una persona juega contra dos o más. Hace un movimiento y no se queda esperando la respuesta del oponente en ese tablero, sino que pasa al siguiente y realiza un movimiento ahí. De esa forma, trata las partidas (tareas) de forma concurrente, lo que resulta en que se terminen en menos tiempo.Seguro están pensando:  Un momento… esto se parece a un threadLo que nos lleva a nuestra próxima sección…Corrutinas vs ThreadsLa diferencia fundamental entre corrutinas y threads se da en la forma en la que se lleva a cabo la multitarea.Los threads, como ya vimos, manejan un esquema de multitarea apropiativa (en inglés, preemptive multitasking), donde el planificador es el encargado de asignar intervalos de uso de CPU a los threads que se están ejecutando, desalojándolos cuando este termina.Las corrutinas, en contraposición, permiten tener multitarea cooperativa (cooperative/non-preemptive multitasking). Esto significa que el cambio de contexto no es controlado por el planificador, sino que cada corrutina es la encargada de ceder el control cuando está inactiva o bloqueda.Otra diferencia, presente al menos en la visión “tradicional” de corrutinas, es que las corrutinas proveen concurrencia pero no paralelismo. De esta forma, evitan problemas de concurrencia, ya que corren en un único contexto de ejecución, y además controlan cuándo se suspenden (en vez de que el planificador las interrumpa en puntos arbitrarios).Una ventaja más que las corrutinas tienen sobre los hilos es que su funcionamiento no involucra llamadas al sistema bloqueantes para su creación ni para el cambio de contexto, ya que todo se maneja al nivel de la aplicación.Interesante comparación de cuando usar corrutinas y cuando usar threads en Kotlin¿Cómo se declaran y ejecutan en Python?import asynciodef print_loco(algo):  return print(algo,'loco')async def print_re_loco(algo):  return print(algo,'loco')  print_loco  &lt;function print_loco at 0x7fe7aa5a9310&gt;  print_re_loco  &lt;function print_re_loco at 0x7fe7aa5a93a0&gt;Las dos funciones lucen similares, la diferencia vamos a notar cuando las usamos:  print_loco(‘bla’)  bla locoNada fuera de lo esperado.  print_re_loco(‘algo’)  &lt;coroutine object print_re_loco at 0x7fe7aa5e8640&gt;Nos retorna un objeto “corrutina” que por defecto no se va a planificar. Entonces, ¿cómo hago que se ejecute? Bueno, hay tres formas distintas para hacer eso.1- Usando la función run del módulo asyncio  coro = print_re_loco(‘algo’)  asyncio.run(coro)  algo loco2- Usando await en una corrutinaimport asyncioasync def say_after(delay, what):  await asyncio.sleep(delay)  print(what)async def main():  await say_after(1, 'hello')  await say_after(2, 'world')  asyncio.run(main())  hello  worldNota: acá usamos run para ejecutar la corrutina main y await para ejecutar las corrutinas say_after.3- Con la función create_task de asyncio, que ejecuta corrutinas concurrentemente wrappeándolas en Tasks, usando  por detrás un event loop para planificarlas.import asyncioasync def main():  task1 = asyncio.create_task(say_after(1, 'hello'))  task2 = asyncio.create_task(say_after(2, 'world'))  await task1  await task2Nota: create_task envía la corrutina al event loop, permitiendo que corra en segundo plano. gather hace algo muy parecido, pero podemos decir que es conveniente usarlo cuando nos interesa hacer algo con el resultado de las corrutinas.¿Qué pasa si ejecuto código bloqueante dentro de una corrutina?Si observaron con detalle se habrán dado cuenta de que cuando se usa sleep para suspender a la corrutina, se esta usando asyncio.sleep en lugar de time.sleep. Esto es porque el segundo es bloqueante. Entonces como ya dedujeron, las operaciones bloqueantes bloquean todo el thread del sistema operativo subyacente.Pero hay formas de evitarlo :D!, lo que se hace es que correr estas tareas bloqueantes y otras que vamos a llamar CPU-bound-intensive, sea conveniente ejecutarlas en otro thread. Concretamente en Python usando loop.run_in_executor() Running Blocking CodeNota: también es posible setear un timeout para que cuando se cumpla, se corte su ejecución ver timeouts .Bonus!Corrutinas y GeneradoresSi bien ambos pueden ceder múltiples veces, suspender su ejecución y permitir el reingreso en múltiples puntos de entrada, difieren en que las corrutinas tienen la capacidad para controlar dónde continúa la ejecución inmediatamente después de ceder, mientras que los generadores no pueden, estos transfieren el control de nuevo al generador que lo llamo. Es decir, dado que los generadores se utilizan principalmente para simplificar la escritura de iteradores, la declaración de rendimiento en un generador no especifica una rutina para saltar, sino que devuelve un valor a una rutina principal. Explicación de yield y comparación con corrutinas  Esta bien, pero entonces.. ¿qué es un generador?Un generador es un tipo especial de subrutina, pensando en teoría de conjuntos, podemos decir que el conjunto generador es un subconjunto de corrutina, por eso a veces son llamados como “semicorutinas”.Un iterador es un objeto que permite al programador recorrer un contenedor (colección de elementos) por ejemplo una lista. Una manera de implementar iteradores es utilizar un generador, que puede producir valores para quien lo llama varias veces (en lugar de devolver sólo uno).A continuación se puede ver un ejemplo de un generador que devuelve los números de Fibonacci:def fibonacci():  a, b = 0, 1  while True:    yield a    a, b = b, a+bfor numero in fibonacci():  # Utilización de generador como iterador  print(numero)Corrutinas basadas en generadoresSin embargo, todavía es posible implementar corutinas basadas en generadores, de hecho, hasta Python 2.5 las corrutinas estaban hechas de esta forma, con la ayuda de una rutina de despachador de nivel superior (un trampolín, esencialmente) que pasa el control explícitamente a los generadores secundarios.def coro():  hello = yield \"Soy una corrutina\"  yield helloc = coro()print(next(c))print(c.send(\", basada en generadores\"))Links interesantesCorrutinas en PythonFramework de Python que levanta un server asincronico con corrutinas planificandolas con un event loopCorrutinas en GoPara jugar con GoroutinesCorrutinas en KotlinComparación de técnicas programación asincrónica (threading, callbacks, Promises, corrutinas). Claramente enfocado para resaltar las ventajas de las corrutinas en Kotlin, pero de todos modos interesante para repasar las técnicas que vimos hasta ahora.",
        "url": "/iasc-book/coroutines/"
      }
      ,
    
      "cps": {
        "title": "CPS",
        "content": "IntroduccionEmpecemos de a poco y por algo muy simple: una función que incrementa en una unidad a su argumento, la función succesor.  Nota: cuando decimos función lo decimos en el sentido estricto de una computación que toma un valor y devuelve otro, sin tener ningún tipo de efectoEn JavaScript, su código se ve como el siguiente:function succesor(x) {  return x + 1;}Usar esta función no tiene mucho misterio:var i0 = 0;var i1 = succesor(i0);…etc…La función succesor está escrita en lo que se conoce como estilo directo: los resultados de la misma (en este caso, su entrada más uno) se obtienen a partir de su retorno.Hasta acá nada extraño. Hagamos ahora un salto conceptual: otra forma posible de escribir este código, es que el resultado se obtenga a partir de un callback.function succesor(x, callback) { callback(x + 1);}¿Y cómo la usamos?var i0 = 0;succesor(i0, function(resultado) { var i1 = resultado; //...etc...});¡Momento! ¿Qué fue eso? Si bien puede verse un poco perturbador al principio, este código es totalmente equivalente al anterior: cuando se aplica la función succesor, calcula su siguiente, y se lo pasa al callback, que opera con el mismo normalmente.  Si te estás preguntando hacia dónde vamos y qué tiene todo esto que ver con la concurrencia, ¡danos uno rato! Prometemos que pronto todo tendrá sentido.A este callback se lo llama continuación. Porque… ¡es lo que que se ejecuta a continuación! O en inglés: continuation.¿Qué significa esto? Que las funciones que toman continuaciones, no solo ahora saben lo que tienen que hacer, sino también cuándo se ejecutará lo que siga. Por eso decimos que una función escrita de este forma tiene, además de la lógica de negocio, control de flujo (o simplemente llamado control).Peeeero, para que esto sea realmente posible, tenemos que tomar ciertas precauciones, y entender que al trabajar de esta forma, el resultado sólo se puede obtener dentro de la continuación.Por tanto, el siguiente es un code smell:var i0 = 0;var i1;succesor(i0, function(resultado) {  i1 = resultado;});//..resto...Aquí estamos capturando el resultado de successor a través de la continuación, asumiendo que el código se ejecutará inmediatamente y que estará disponible en la línea 6.Pero si es realmente successor quien tiene control sobre cuándo y cómo se ejecuta la continuación, no podemos garantizar esto dado que no sabemos cuándo se va a ejecutar la continuación.¿Esto significa que el código anterior no funciona? No, pero tenemos que entender que estamos rompiendo el modelo de continuación, al no permitir que sea la función successor la que determine cuándo y cómo seguir. Y eso puede ser una fuente de bugs.ConsecuenciasEn oposición al estilo directo, caracterizado por la obtención de resultados mediante retornos, surge así el estilo de paso de continuaciones (CPS, por sus siglas en inglés). Es decir, cuando tenemos una función que toma una continuación y efectivamente colocamos todo el código que opera con el resultado dentro de la misma, tenemos una función CPS.El CPS es especial porque es fácil introducirlo, pero imposible salir de él, al menos no sin introducir bugs y potenciales problemas en el sistema.Retomando las ideas de nuestro primer episodio, esto es una propiedad interesante: una vez impuesta la arquitectura, no tenemos opción de escapar de ella, lo que nos resta en flexibilidad, pero nos fuerza a ser consistentes.Ejemplo: si ahora queremos implementar una función que incrementa el doble de un número, usando nuestro successor CPS, estaríamos tentados a escribir esto:function incrementarDoble(i) {  var i0 = 2 * i;  succesor(i0, function(resultado) {   var i1 = resultado;   ???  });}Y ahí vemos el problema: incrementarDoble debe retornar i1, ¡pero no puede hacerlo, porque no hay garantías de cuando se va a ejecutar la continuación, ni cuantas veces!Por ello, la única alternativa válida (sin basarse en los detalles de implementación de successor, claro), es convertir a incrementarDoble en CPS también:function incrementarDoble(i, cont) {  var i0 = 2 * i;  succesor(i0, cont);}Moraleja: una vez que introducimos CPS, su uso sólo puede extenderse.  Esto no significa que no podamos tener computaciones no CPS. Por ejemplo, la multiplicación podría ser extraída como una función en estilo directo. Desarrollaremos esta idea arquitectural mejor en próximos episodios cuando ataquemos el mundo monádico.¿Para qué CPS?Resulta bastante evidente que razonar sobre CPS es más complejo que en el estilo directo. Entonces, ¿por qué habríamos de adoptarlo?CPS, al otorgarle a la función no sólo capacidad de cómputo sino de control, permite hacer cosas muy poderosas. En los ejemplos anteriores no lo aprovechamos, porque la computación succesor puede ser modelada con una función con un sólo resultado posible:function succesor(x, cont) { cont(x + 1);}Pero sin embargo, podríamos haber aplicado a la función cont cero (1) o muchas veces (2), podríamos haber recibido múltiples continuaciones y ejecutar alguna de ellas (3), o podríamos haberlas ejecutado en otro momento (4). CPS nos permite, entones, implementar 4 tipos de computaciones: con falla, no determinísticas, con excepciones y asincrónicas.  Recordar estos tipos de continuaciones, volverán en episodios futurosFallaCon CPS podemos codificar computaciones que pueden no tener resultado (los matemáticos las llaman funciones parciales). Por ejemplo, la división es una función parcial que no tiene un resultado cuando su segundo argumento es cero, por lo que podemos definir una función inversa CPS de la siguiente forma:function inversa(x, cont) {  if (x !== 0) {    cont(1/x);  }}Si ahora aplicamos a inversa con el valor 2, tendremos como resultado 0.5. Pero si la aplicamos con 0, no tendremos resultado. Esto no es lo mismo que no devolver nada en una función en estilo directo (o devolver null): en una función CPS que puede fallar, si no hay resultado, el programa continuación NO continúa; el flujo de ejecución se detiene.No determinismo.Hay computaciones que pueden arrojar cero o más resultados, son la generalización de la función: la relación. Por ejemplo, la pregunta ¿quien es hijo de Vito Corleone? (notá el singular) tiene múltiples respuestas: Sonny, Michel, Connie, etc.Esta es la base del paradigma lógico: relaciones que pueden generar ningún resultado, uno, o varios.function hijoDeVito(cont) {  cont(\"sonny\");  cont(\"michel\");  cont(\"connie\");  cont(\"freddo\");}Se observa fácilmente que logramos las múltiples respuestas mediante la aplicación reiterada de la continuación: el mismo programa está continuando múltiples veces con argumento diferentes.CPS no nos da una restriccion sobre la cantidad de veces a las que se deba llamar la continuacion que recibe. Por lo que vamos a poder aplicar la continuacion 0 o múltiples veces.Tal vez el ejemplo de recien no fue tan convincente…. bueno tenemos el ejemplo mas basico que podemos encontrar en la documentacion de Node.js:const http = require('http');const hostname = '127.0.0.1';const port = 3000;const server = http.createServer((req, res) =&gt; {  res.statusCode = 200;  res.setHeader('Content-Type', 'text/plain');  res.end('Hello World');});server.listen(port, hostname, () =&gt; {  console.log(`Server running at http://${hostname}:${port}/`);});  Shamelessly taken from hereEste pequeño ejemplo nos muestra claramente el no determinismo, porque es un servidor que podemos levantar, y nunca vamos a saber cuantos request nos van a llegar al servidor durante el tiempo que este levantado, tal vez recibimos 28392389 requests, tal vez 0.ExcepcionesTodos conocemos las excepciones. Estas nos dan dos flujos de ejecución: uno de éxito y uno de fracaso, y en ambos hay resultados: el resultado normal del programa o el error en cuestión. Y esto lo podemos lograr pasando dos continaciones: la que contiene el flujo normal, y la que contiene el flujo de error.Computaciones asincrónicas.¡Éstas son las que más nos interesan! Operaciones que quizás no se ejecuten inmediatamente, sino en un momento posterior. Más sobre esto, en breve.CPS, ¿y Callback Hell?Un pequeño paréntesis: se suele achacar al uso de CPS la inevitable caída en el callback hell. Por ejemplo:var cuentaLoca = function(x, cont) {   siguiente(x, function(y){    inversa(y, function(z){      duplicar(z, cont);    })  })};Como se observa, algo tan simple en estilo directo comoduplicar(inversa(siguiente(x))) se convierte en una compleja estructura de continuaciones anidadas.¿Podríamos delegar esto de mejor forma? Si analizamos cómo queda expresada esta computación en estilo directo, podemos ver que duplicar la inversa del siguiente, a fin de cuentas, está describiendo una composición de funciones: al resultado de aplicar una función se le pasa a la entrada la otra.Obviamente, no es la misma composición de funciones que conocemos en estilo directo: es una composición CPS. Y entender esto nos permite definir una función componer, que haga justamente esto: function componer(f, g) {     return function(x, cont) {         g(x, function(y){             f(y, cont);         })     } }y una vez que tenemos eso podemos ya utilizarla así:var cuentaLoca = componer(duplicar, componer(inversa, siguiente))Y si le damos una vuelta de tuerca más, podemos observar que estamos ante la estructura de aplicación de un fold, y definir una función pipeline que componga todas las funciones cps function pipeline(fs) {     return fs.reduce(componer); }Con este pipeline podemos reutilizar el componer aplicandole un fold sobre un array y de esta manera que se puedan componer todas las funciones que tenemos sin caer de nuevo en el Callback Hell:var cuentaLoca = pipeline([duplicar, inversa, siguiente]);Y así vemos como eliminar el callback hell, aun con CPS, es posible.Moraleja: no es culpa del CPS, es culpa nuestra al no delegar convenientemente.Conclusiones  CPS nos da gran poder, pero es difícil de manejar adecuadamente  CPS nos lleva, si no tenemos cuidado al callback hell. Sin embargo, no es inherente a CPS, sino que es consecuencia de una mala delegación. Es posible resolverlo si se delega apropiadamente y aplicando los conceptos de programación funcional de orden superior y creando combinadores apropiados  CPS nos permite implementar computaciones asincrónicas. NodeJS emplea CPS para soportarlas.  El uso de CPS en NodeJS: pésimo manejo de errores y ausencia de abstracciones para hacerlo mas tratable. Por eso es que la comunidad centró su atención en otra forma de estructurar programas con influencias funcionales: las promesas (promises).",
        "url": "/iasc-book/cps/"
      }
      ,
    
      "distribucion": {
        "title": "Distribucion",
        "content": "DistribuciónIntroduccionAntes de hablar de distribución, es a veces ideal tratar de explicarlo de cómo se llega a ella. En general cuando se plantea la arquitectura de una aplicación, en cuanto a la arquitectura, en donde queda afuera lo que es el diseño e implementación del mismo, en general se plantea o se despliega por primera vez como un monolito, es decir, solo implementar todo nuestro sistema en un solo servidor. Ya sea un prototipo, o una versión temprana (beta) de nuestra aplicación, en general se plantea el monolito como arquitectura inicial, por costos y tiempo en el que se despliega la aplicación, y también porque no tenemos problemas que nos puede causar un sistema distribuido.Esta es una imagen de una arquitectura monolitica tradicional, con una aplicacion y una base SQL, que en general esta desplegada en un solo servidor. Algunos problemas que puede generar esta arquitectura es la siguiente:  Incremento de la complejidad de la aplicacion, a medida que pasa el tiempo y la misma empieza a tener gran cantidad de componentes o va creciendo los requerimientos del sistema  Cuando empieza a ser usado cada vez por más usuarios, esto hace que aumente la carga y que un solo servidor pueda no ser suficiente o incluso generar problemas con la carga que generan estos usuariosAnte el aumento de la carga de usuarios, tráfico y mayor interacción entre la aplicación y la base de datos, esto genera una carga mayor en el único servidor que tenemos, por lo cual deberemos escalar. Hay dos tipos de escala:Escala Vertical (Scale Up)Esta manera de escalar, también conocido como escalar para arriba o verticalmente (?) (scale up), es incrementando los recursos de un servidor o un nodo, o sea aumentar CPU, memoria, disco, etc. Lo que nos permite este tipo de escala es que no necesitamos realizar cambios o desarrollo adicional en nuestro sistema, solo habrá un tiempo en el que nuestro sistema no estará disponible hasta una vez que hayan sido implementado estos cambios. El problema de escalar verticalmente es que el costo empieza a ser exponencial en un momento, por lo que en un momento se puede hacer muy costoso un nodo único muy grande en donde cada vez las mejoras van a ser menores en cuanto a recursos.También hay un momento en el que, si utilizamos servidores tradicionales y no mainframes, exista una limitación en cuanto a la tecnología, en general por limitaciones en cuanto a la CPUsEscala HorizontalLa otra manera de escalar, es horizontalmente también (Scale Out) es cuando en vez de incrementar los recursos, se agregan nuevos servidores con los mismos recursos. Lo bueno de poder escalar horizontalmente es que la aplicación no deja de estar disponible al escalar de esta manera. El costo con esta metodología es mucho más económica por este medio, que escalando verticalmente, otro aspecto interesante es que es más tolerante a fallos, ya que más copias de la aplicación están corriendo al mismo tiempo. Las grandes desventajas son que la arquitectura se complica, junto con el aumento del ancho de banda entre los distintos componentes que puede llegar a tener nuestro sistema una vez que hagamos scale out.Con respecto a nuestra aplicación monolítica, podemos bien o replicar toda la aplicación con su bbdd, y que no tengan relación alguna cada una de las maquinas (imagen izquierda), o bien podemos solo replicar en cada uno de los servidores la aplicación y luego tener en otra instancia nuestra bbdd (imagen derecha).La motivación para la arquitectura de la imagen de la izquierda puede ser que se quiera distribuir por países el sistema, o sea, que en cada país que exista esta aplicación se dirija a un servidor que contiene todo su estado. La otra manera de escalar horizontalmente nuestro monolito nos permite que no tengamos tres bases de datos distintas, y que incluso el sistema pueda ser visto aun por el usuario como uno solo, o sea generalmente mediante alguna diferencia de endpoints, pero… como manejar la carga de manera que no se sobrecargue un solo servidor y los otros no?  Con un load balancer…Un load balancer nos va a permitir usar alguna estrategia por la cual la carga sea distribuida de manera equitativa. Esto puede ser por un algoritmo simple, tal como puede ser un round robin, o puede tener algún feedback de los nodos o servidores, que pueden dar al load balancer un poco más de información sobre a dónde redirigir el tráfico.Pero esta es la única manera de escalar?? La respuesta es no.Se puede escalar horizontalmente de varias maneras, existe un libro que es el de “Art of Scalability” de Michael Fisher que nos propone un interesante modelo de cubo de como escalar.En esta representación el punto de origen concuerda con el sistema monolítico en una sola instancia, y la arista de arriba a la derecha del cubo, nos representa la máxima escalabilidad de la aplicación. Y como el cubo es en tres dimensiones, eso nos dice que no solo hay una manera de escalar nuestra aplicación sino que hay varias que incluso podríamos llegar a combinar, ahora veremos cada una de las dimensionesEje X - ClonacionEsta manera de escalar, es la que vimos al final de la sección anterior, es cuando tenemos varias réplicas de nuestra aplicación monolítica y que pueden o bien acceder a una bbdd. Otros temas a mencionar que no se hayan hecho antes es el tema de que al existir varias copias de nuestro sistema, tendremos que de alguna manera garantizar que los datos se mantengan consistentes, ya que varias copias van a estar accediendo a los mismos datos, por lo que tendremos que bien o implementar un sistema de lockeo de los datos o usar algo que nos garantice esto, que bien puede ser la base de datos.Este esquema no nos resuelve aún el problema de una aplicación de alta complejidad, o sea.. Que aun nuestro código va a estar aun organizado como una aplicación monolítica, esto puede no ser una desventaja si no tenemos un basecode demasiado grande pero si lo fuese, por temas de complejidad o incluso de uso de servicios de terceros, tal vez sea un problema a nivel de desarrollo o mantenimiento.Eje Y - Descomposición FuncionalEn vez de tener varias instancias o nodos del mismo sistema, cada uno conteniendo todo el código del sistema, en este eje se va a descomponer nuestra aplicación entre los distintos nodos, esto es lo que se conoce generalmente como microservicios, y cada uno de estos va a ser responsable de una función.Y como podemos descomponer a nuestra aplicación?      Podemos descomponer por medio de la función técnica de lo que hace ya sea un endpoint, o una funcionalidad, por ejemplo, se puede descomponer una aplicación en servicios de capacidad (capability-services) como login, usuarios, productos, etc. Abajo hay un pequeño ejemplo de un servicio de discusión, estilo reddit.        Otra manera de descomponer es dividir por dominios a la aplicación, o sea por los recursos pero como un todo, y no por las funcionalidades, o sea si tenemos una aplicación de venta, podemos dividir la aplicación en: servicio al cliente, ventas, catalogo para el usuario. Esta división es más bien por entidades (Entity-Services)  También pueden combinarse esta división o usarse otro tipo de división del sistema, el esquema no es estricto en este sentido, por lo que nos da la libertad de escalar nuestra aplicación o más bien de dividirla de acuerdo a nuestro dominio. No hay ya necesidad de clonar toda la aplicación de esta manera. El problema es que esto genera otras desventajas y son que ahora nuestros microservicios además de trabajar con la bbdd a veces tendrán que coordinarse los unos a los otros mediante mensajes o requests incluso, también puede haber un incremento en el uso del ancho de banda.Eje Z - Sharding/Data PartitioningHasta ahora vimos cómo dividir nuestro sistema pero a nivel de organización de la lógica de nuestros componentes, puede existir el caso en el que si estamos persistiendo los datos de nuestro sistema, el mismo aún tenga una sola base de datos o a lo sumo este replicada en otras bases, pero que en suma estas réplicas son solo una copia de todo el estado de la base de datos principal, por lo que en ese esquema solo una base de datos admite escrituras y todas puedan ser leídas. Dependiendo del tipo de réplica, la misma puede ser hecha ni bien se escriben los valores o a veces pueden tenerse escrituras que no garantice que una vez que se escribió el valor en la base de datos, el mismo esté replicado en las otras bases, esto se llama replicación asincrónica. Pueden ver mas de esto en el siguiente (link)[https://www.cybertec-postgresql.com/en/services/postgresql-replication/synchronous-synchronous-replication/]Pero aún tenemos el estado, a lo sumo replicado, tal como lo teníamos con los servidores al escalarlo mediante clonación (eje x), y solo podemos tener una escritura a la vez, esto puede ser un cuello de botella si existen muchas escrituras sobre la base de datos. El esquema de este eje z, es el de dividir la base de datos o el estado en subsets, por lo que podemos dividir el estado bajo un criterio determinado, por ejemplo si tenemos un estado que son los productos, bien podemos dividir los mismos por rango de letras como el siguiente ejemplo.Y como tenemos ahora el estado particionado, vamos a tener que tener algo que nos pueda despachar al nodo correcto los pedidos de lectura o escritura, que puede ser un load balancer, o bien que los nodos de estado o persistencia se puedan hablar entre ellos para devolver o persistir el estado, esto último es en el caso en el que no se tenga una base de datos relacional o tan solo se pueda implementar un shardeo de este tipo.Lo interesante de este esquema es que no tenemos más de un nodo de datos que pueda aceptar escrituras, aunque solo habrá una escritura por subset.Combinación de EjesComo el modelo de escala es tridimensional, se puede incluso combinar para que nuestra arquitectura sea más robusta, por ejemplo, podemos tener un esquema de microservicios en el que además cada servicio, como el de login, puede esta clonado y tener más de un servicio de login disponible y el mismo esté tan solo distribuido por un segundo nivel de load balancer que redirige los request con un criterio, que nos da un esquema así? Como dijimos antes, mayor robustez, si bien escalar por microservicios divide la carga, aun todos los usuarios en gran medida, deberán loguearse, y ademas al separar los servicios, aun seguimos teniendo un solo punto de fallo, por lo que para que el servicio esté disponible si el servidor de login se cae, es el de escalar después este microservicio por medio de clonar el mismo en varios servidores idénticos con este microservicios.SesionesOtro tema que no hablamos antes es sobre las sesiones en nuestra aplicación ahora distribuida, en el primer caso que es el de replicar la aplicación, si tenemos varios nodos con toda nuestra aplicación y un load balancer, puede ocurrir que un usuario se loguee en un nodo y luego en otro request, pueda ser redirigido a otro nodo donde no se tiene registro de su login, como se resuelve esto? O bien teniendo un lugar, como una base de datos aparte donde se registren las sesiones o bien se puede optar por un esquema de sticky sessionsELs sticky sessions permiten mediante una cookie, saber contra qué servidor se autenticaron, además de otra información de la sesión, el load balancer sabe a qué nodo redirigir los requests de un usuario en particular sobre un modelo de cloning o en el que nuestra aplicación esta solo replicada, en otros tipo de arquitecturas como microservicios, puede ser que no sea necesario a menos que exista solo nodo de login de usuarios.Heartbeat y gossipA veces es necesario saber si un nodo o servicio esta disponible y que sepamos que no este caido, a veces si es solo un servicio que estamos exponiendo podemos tan solo tener un healthcheck, que es solo un endpoint de nuestro sistema,( algo mas de detalle en (https://microservices.io/patterns/observability/health-check-api.html)[https://microservices.io/patterns/observability/health-check-api.html], puede ser incluso implementado si no estamos en un esquema de microservicios) para confirmar si nuestro servicio esta disponible y puede admitir nuevos pedidos, pero esto es en general a nivel de HHTP, por lo que si un nodo nuestro se cae podriamos no llegar a poder responder un request hecho a nuestro endpoint. Entonces cómo podemos detectar fallas en nodos de nuestro sistema si no es solo mediante un chequeo de healthcheck o un mecanismo similar? Podemos hacerlo mediante conexiones de tcp en las que se pase un token o un bit o un valor que se van a ir pasando entre los nodos, y de esta manera cuando un nodo deje de pasar ese valor después de un tiempo prolongado, muy superior al tiempo entre emisión de este valor, se puede tomar al nodo como caido.Esto se lo conoce como heartbeat, y es útil para conocer si se cayeron los nodos sin depender de un healthcheck, ya que pudo existir una caída del nodo y que no sea un problema lógico o de algún componente o servicio externo. Lo recomendable es que la información de heartbeat este en una vía o conexión distinta a lo que se usaría para intercambiar información entre nodos o servidores.Otra manera un poco mas bien ordenada o distribuida, de cómo notificar a otros servidores y no hacer múltiples conexiones entre nodos, para usar heartbeat, es el de usar un protocolo de gossip. Esto permite que se intercambie más información entre servidores, y que no sea solo un simple valor o bit, por ejemplo, puede ser información tal como por ejemplo: “se cayó el nodo de login x”, o “volvió a estar disponible el nodo que contiene la base de datos”. Se puede encontrar un poco más de información en el siguiente (link)[https://github.com/gossiperl/gossiperl/wiki/gossip-in-computer-science]Distribución en Elixir/Erlang (BEAM)Cuando hablamos de distribución en general, en general estamos solos sin ayuda de algún componente del lenguaje que estamos usando, es decir, estamos solos en la oscuridad sin saber qué es lo que puede suceder. Con erlang/elixir, a pesar de que posee mecanismos como los que vimos, tampoco estamos con mucha más ayuda del lenguaje, o sea seguimos en la oscuridad. Elixir nos da ventajas para tolerancia a fallos y resiliencia pero no mucho más que eso. Cuando se implementó Erlang muchas de las consideraciones que veremos hoy no se tomaron en cuenta por un tema de que la arquitectura en la que fue concebido es distinto a lo que hoy conocemos.Elixir posee algunas cosas base por la cuales podemos utilizar como fundaciones para construir aplicaciones distribuidas, que ya vimos interconectando máquinas virtuales entre si, como serializar datos (van a tener que ver la api para esto), y como saber cuando un nodo se cae (esto lo vemos pronto), pero no sobre soluciones específicas como que pasa cuando un proceso se cae o algo falla inesperadamente en una maquina. O sea OTP nos da muchas herramientas para ir manejando y construyendo estas herramientas pero no existe una en particular para solucionar todos los problemas puntuales de nuestra aplicación Erlang/Elixir, o sea no hay bala de plata.Una instancia de la máquina virtual de erlang, que está lista para comunicarse con otras vm’s las llamaremos nodos. Cuando se inicializa un nodo, se le da un nombre en concreto como vimos con el caso del ping pong y este se conecta a una aplicación llamada Erlang Port Mapper Daemon (EPMD), que ejecuta en cada una de las máquinas que son parte del cluster que estaremos armando, si es el caso que es más de una máquina. EPMD actuará como un name server que permite que los nodos se registren, se contacten con otros nodos y notifiquen cuando hay algún conflicto de nombres.De esta manera ya podemos empezar a conectar uno nodos con otros, y ver como empiezan a haber comunicación entre estos, un primer approach que se puede ver es que si se tiene un nodo A y otro B solo con una conexión y uno de estos se cae, el otro nodo queda aislado.Si B estaba comunicado con C y necesita procesar algo que puede solo hacerlo A y B solo lo hacia delegando a A, esta funcionalidad ya no funciona ya que A esta aislado. Una primera idea es interconectar a todos con todos. Esta idea podría ser interesante, más que nada por una cuestión de tolerancia a fallos, pero sucede que puede ser un problema si la aplicación escala y se necesitan interconectar más nodos. Será dificil de tener cientos y cientos de nodos interconectados en sí más que nada por la cantidad de conexiones que necesitan, también hay que recordar que se necesita un puerto por nodo al que se está conectando. La topología más común a esto es hacerlo en forma de anillo, algo parecido a lo que hay en token ring, pero sin el token.Una vez que se conectaron los nodos, estos son ya independientes, poseen su registro del proceso, sus tablas de ETS y módulos independientes unos de otros. Un nodo cuando se cae no hace que se caigan los nodos asociados. Lo interesante de la conexión entre nodos es que se pueden mandar mensajes de la misma manera en la que se lo hace entre procesos de un mismo nodo. La serialización/deserialización lo hace automáticamente y de manera transparente el nodo. Veremos que las estructuras incluidas los pids funcionan de la misma manera remotamente como localmente, esto significa que puede mandarse mensajes de pids sobre la red y comunicarlos mediante mensajes.Bonus: Mitos de la distribuciónDurante muchos tiempo, existieron 8 leyes o enunciados principales que son falacias y que son difíciles de manejar y la gente de erlang tomó algunas decisiones cuando se diseñó el lenguaje en sí.      La red es confiable: Esta es la primera falacia que hay en la computación distribuida, pueden existir fallos de red bastante más frecuente de lo que uno cree, más acá que en otros lados incluso por muchas razones (cortes de luz, falla de hardware, cable roto, etc). Entonces ya de por si no es verdadero que uno puede interconectar dos nodos en una red y siempre esperar que uno desde un nodo se puede conectar y hablar normalmente con otro nodo. Erlang en si no tiene un mecanismo especial para eso, lo mejor que nos provee es que haya una comunicación asincrónica en la que se manden mensajes asincrónicamente y después de un timeout se reintente o falle, entonces si un nodo se cae, lo manejaremos como si fuese un fallo local.        No hay latencia: Esta es otra falacia ya que de por sí a menos que estén todos los nodos en una sola máquina, siempre existe la conocida latencia de red, e incluso si los nodos estuviesen localmente existe una pequeña latencia. Erlang de la manera en la que es, teniendo nodos como procesos aislados e independientes, mensajes asincrónicos, timeouts, monitores, nos permite ir manejando y viendo cómo ir tratando de manejar la latencia entre los distintos nodos e ir ajustando esto dependiendo de la red.        El ancho de banda es infinito: Si bien el ancho de banda es mucho mayor que hace unos años, no hay que ir pasando exceso de información o gran cantidad de información entre dos nodos, siempre hay que tener en consideración que una comunicación entre dos nodos pasa en general mediante una conexión de TCP y solo una. Entonces todos los mensajes que mandemos pasarán por un solo canal entre dos nodos, entonces pasar un mensaje muy grande puede generar un bloqueo para otros mensajes consecuentes en este canal y crear un cuello de botella. Además Erlang/Elixir tienen un mecanismo para saber que los nodos están aún vivos que se lo conoce como heartbeat, y funciona de manera en el que los nodos  conectados mandan mensajes cortos entre sí para avisar que aún están vivos y levantados y pueden hablar entre sí llamados beats. Estos mensajes se pasan por el mismo canal que los mensajes comunes entonces bloquear el canal con un mensaje muy grande puede generar que se bloquee el mensaje de beat y luego de pasado un tiempo que se rompa el vínculo entre los nodos.        La red es segura. Acá no hay mucho que explicar, sabemos que la red es bastante insegura hoy por hoy. En general las aplicaciones se arman en clusters en una red local, y en general hacerlo en nodos en diferentes lugares físicos no está recomendado, de tener que hacerlo, debería implementar algún mecanismo que no viene por default en Erlang/Elixir, mediante ssl, o implementar el protocolo de comunicación entre los nodos. Hay algunos links que después pasaremos de esto.        La Topología no cambia. Uno puede diseñar una aplicación distribuida en una LAN o intranet con una cantidad de máquinas con IP fija y una red pre-establecida, pero la realidad es que.. el hardware cambia con el tiempo, se hacen migraciones de red, o se cambia como era la topología de la LAN o inranet. Entonces sucede que no se puede hardcodear la ip de las máquinas al interconectarlas, para eso, Erlang identifica mendiante username a los nodos, hay un mecanismo que no veremos pero que existe llamado cookies que permite que se pueda identificar a un nodo con un username, no hay que confundirlo con las cookies de http pero son algo similares, aunque nunca deben considerarse un mecanismo de seguridad.        Solo hay un administrador. Esto se cae muy rápido en los caso que tengamos una gran cantidad de servidores o incluso cuando nuestro sistema empieza a escalar, como vimos para volver a levantar procesos en Erlang es dentro de todo bastante simple aunque debe hacerse por medio de un administrador o persona si el nodo se cae definitivamente.        El costo de transporte es cero. Lease esto como costo de transporte de datos de un nodo a otro en términos de tiempos y/o dinero. Serializar los datos no es gratis o rápido a veces, y la red posee una latencia también como mencionamos que acarrea un costo. En cuanto a costo monetario, siempre hay costo de mantenimiento de la red, servicio de ISP, hardware, personal.        La red es homogenea. Esto último se refiere a que siempre usamos los mismos formatos para operar todo junto. Esto se refiere a que siempre se usa un mismo estándar y no siempre es así, se usan distintos lenguajes y estándares (XML, JSON, no no vamos a compararlos aca), pero en Erlang se tiene en cuenta que siempre nos vamos a comunicar y hablar con nodos y nuestro sistema está en el mismo lenguaje y que hablan el mismo protocolo. Entonces volvemos a un concepto como duck typing, en la que si tenemos un nodo que está implementado en otro lenguaje pero usa el mismo protocolo que erlang, entonces podrá hablar con otros nodos, un caso es cnode.Otra manera de intercambiar información es mediante BERT-RPC, cualquier otro sistema que use esta implementación podrá pasar información a un nodo erlang/elixir.  Interleaving y netsplitsSucede a veces cuando tenemos una interconexión entre nodos, momentos en los que tal vez un nodo no empieza a responder a los heartbeats y perdemos conocimiento de él, después de un tiempo tendremos que asumir que esta muerto. En general se asume, y también en lenguajes que nos ayudan con algunos temas de distribución como Erlang, que si un nodo no se puede conocer si está vivo, está muerto, que es el caso más pesimista que es cuando se piensa que hay más fallos de hardware/software que de red. Otro esquema sería el optimista en el que el nodo está vivo y en realidad lo que pasó es que por un momento la red se cayó o había demasiada latencia y no llegaba al nodo extraviado. Este esquema supone que es más frecuente el fallo de red que de hardware/software. Imaginemos un sitio de compra y venta tipo mercadolibre con dos nodos y sucede este esquema, cuando se realizar una transacción en un nodo, se debe también sincronizar la transacción en el otro nodo ya que puede existir el caso que una de las dos partes tiene su cuenta en otro nodo, si funciona todo bien no hay problemas, pero en el caso de que uno de los nodos no responda, y luego en realidad haya pasado que había un fallo de la red, el nodo queda desincronizado, pero el esquema que tomemos puede tener una desventaja u otra, el pesimista es que no permita que haya transacciones y en consecuencia perdamos plata, no cobramos la comisión, pero el otro caso si es optimista, puede suceder que haya un interleave que deje que dos personas compre un mismo productos en los dos nodos y después no se sepa quien ganó.",
        "url": "/iasc-book/distribucion/"
      }
      ,
    
      "efecto-lado-haskell": {
        "title": "Efectos de Lado en Haskell",
        "content": "Efectos de LadoIntoduccionDurante la clase pasada estuvimos viendo monadas y otros conceptos en haskell como functores y aplicativos. Si bien pareceria que la clase pasada presenta a simple vista una cierta desconexion con respecto a concurrencia, esto no es tan asi ya que una monada puede verse como una computacion que puede llegar a cambiar por un estado valido o invalido a lo largo del codigo.Durante lo que se ha visto hasta ahora en haskell no se ha mencionado nada sobre efecto de lado, y esto es porque se comento seguramente que Haskell es un lenguaje netamente puro, y por ende, sin efecto de lado, esto no es tan asi si se muestra un ejemplo como este en donde se imprime algo por pantalla:import System.IOmain :: IO ()main = do  hPutStr stdout \"Hola mundo!\"Aqui es donde introducimos un cambio en el estado del sistema, y si bien es una impresion por pantalla, algo tan simple como un print por stdout es en si un efecto de lado. Entonces que es lo que consideramos como un efecto de lado?Un efecto de lado es cualquier cosa que lee o escribe un estado mutable. el I/O es un ejemplo claro de esto, ya que estamos pasandole a un handle que es el stdout, una escritura que en el ejemplo es el Hola mundo!veamos la firma de lo que usamos para imprimir algo por pantallahPutStr  :: Handle -&gt; String -&gt; IO ()hGetLine :: Handle -&gt; IO Stringsi bien hay que pasarle un handle, y un string, estariamos devolviendo un IO () y un IO String, la diferencua es que un IO string, es como una caja de IO, que nos permite guardar un valor que puede ser mutable y el tipo que contiene en esa caja es del tipo String, cuando se le pasa los parentesis, significa que hay un tipo, cuyo unico valor es () y que se usa solo para representar que no nos interesa el retorno de la funcion, y esto es porque no hay nada util o necesario que querramos realmente hacer con este valor de retorno, y por eso se usa generalmente para funciones que producen efecto de lado.Genial ahora sabemos que no hay tanta diferencia entre estos retornos. Podemos generalizar esta firma con algo como IO a con un tipo particular, y a esto se le llama en Haskell como actions. por lo que al hacer hPutStr stdout 'hola', es una accion que cuando se ejecuta, va a imprimir hola en el handle que es stdout.Ahora si quisieramos tener mas de una accion, habria que concatenarlas, o sea componerlas, por lo que deberiamos obtener el valor de esta caja que es IO, obtener el valor y utilizarla en la proxima linea por lo que si tenemos que usar el operador &gt;&gt; para concatener por ej una seria de hPutStrmain = (hPutStr stdout \"Hola mundo!\") &gt;&gt; (hPutStr stdout \"Mi segunda linea\")para simplificarlo vamos a usar la do notation:main = do    hPutStr stdout \"Hola mundo!\"    hPutStr stdout \"Mi segunda linea\"Ahora que pasa si tenemos que leer una linea e imprimirla?Con la do-notation:main = do    a &lt;- readLn    hPutStr stdout aparece simple, pero y sin la do-notation, como quedaria?main readLn &gt;&gt;= (\\a -&gt; hPutStr stdout a)tanto » com »= son el binding operator, y este permite que usemos en la proxima accion el resultado del anterior. Esto se parece bastante a lo que vimos la clase pasada,no? Veamos un ejemplo mas para que no queden dudasAhora queremos que de acuerdo a un handle agreguemos un texto antes de leer una linea, o sea un append de una linea antes, para eso arme esta funcion prependpreprend :: Handle -&gt; IO Stringprepend h =     s &lt;- hGetLine h    hPutStr h (\"Linea de prepend antes de la linea leida del handle.\")    return sEsto se puede ver en el ejemplo de SimpleIO.hs y lo que hace es agregar al handle esa linea antes de devolver la linea leida al control. Pareceria muy normal ver ese return ahi, pero en realidad la firma es IO String, por lo que la firma se estaria cumpliendo. Lo que pareceria algo que es del lenguaje, en realidad es una funcion mas, y esta es su firmareturn :: a -&gt; IO aEntonces esta caja IO, puede usar return y binding…. Todo pareceria indicar que es en realidad una monada.Si esto les parece bastante raro pueden ver o preguntarnos sobre que es una monada o ver el material de la clase anterior. En otro caso continuemos.Sobre el efecto de lado, no solamente lo vamos a tener del lado de I/O, a veces queremos por x razones tener una variable mutable, y hasta ahora no podiamos tenerlo en haskell, que podemos hacer ahora que sabemos que IO nos permite encapsular algo que contiene un valor que puede ser modificado con efecto de lado?En este caso seria extenderlo…Por eso estaremos usando lo que nos permite manejar una referencia a algo mutable que es IORefY veremos un ejemplo simple que es el de tener un contador… nada muy elaborado, pero es nuestro ejemplo mas simple que ya vimos y que nos permitira explicar bien que es un IORef ademas de una monada.bien para esto podemos usar un tipo creado o tan solo nuestro contador mutable puede ser un simple IORef Int que podremos crear con newIORef x donde x es un valor, por lo que lo inicializaremos con un valor entero, despues de eso tan solo usando las funciones que tenemos para escribir y leer un IORef de la misma manera que lo haciamos con un IO, que sonreadIORef :: IORef a -&gt; IO awriteIORef :: IORef a -&gt; a -&gt; IO ()vamos a poder ahora modelar nuestra funcion que nos de el sucesor de nuestro contadorincRef :: IORef Int -&gt; IO ()incRef var = do    val &lt;- readIORef var    writeIORef var (val+1)Interesante. Ahora siempre que usemos esta funcion, pasandole un IORef que contenga un Int, va a extraer el valor, y de ahi escribir este IORef con el valor incrementado en 1Lo ultimo para mencionar es que IORef nos permite modelar ahora variables mutables, y puede verse como un puntero a una posicion de memoria mutable.Sigamos… Veamos algo de concurrencia ahora..Introduccion a la concurrencia con ForkVamos a utilizar la funcion forkIO que tiene la siguiente firma forkIO :: IO a -&gt; IO ThreadIdque nos va a permitir forkear el thread actual en uno nuevo y que se ejecuten varias cosas de manera concurrente. veamos un ejemplo simple en fork.hsimport System.IOimport Control.Concurrentmain :: IO ()main = do     forkIO (hPutStr stdout \"Hola\")    hPutStr stdout \" mundo\\n\"Ahora bien al forkear el thread, el segundo se va a ejecutar y como ambos ejecutan hPutStr stdout, ahora es solo no deterministico cual de las dos sentencias se va a ejecutar primero, o sea cual de las dos “ganaria” por ejecutarse primero, y lo mas importante, si necesitaramos que primero se ejecute uno y despues la otra sentencia porque nos importa el orden, esto no podriamos ya garantizarlo. Por otro lado si esto fuese una variable y no un handle de I/O, podriamos estar pisando un valor mutable, modelado con IORef, en un thread mientras que en otro se este utilizando, por lo que ya no estariamos garantizando la atomicidad de mas de una operacion!Para esto entra en juego un mecanismo que nos va a ayudar a manejar el estado concurrente, modelado con variables mutables, entre distintos threads sobre un mismo estado un mecanismo llamado STM.Pueden ver mas informacion de IO aqui",
        "url": "/iasc-book/efecto_lado_haskell/"
      }
      ,
    
      "": {
        "title": "Pagina Principal",
        "content": "Esta es una pagina donde se van a ir actualizando el material y contenido de la materia.ObjetivoUn poco la idea de esta seccion de la pagina de Arquitecturas Concurrentes es la de tener un lugar donde tengamos material para que puedan estudiar o como complemento despues de la clase. La idea es que esta pagina se vaya actualizando y ampliando de manera iterativa e incremental :)KISSLa idea es tener una UI bastante basica, y que solo sea lo minimo indispensable para mostrar lo que mas nos importa, que es mostrar contenido sobre algun tema puntual de la materia.Got typo?Si alguno detecta algun problema o error puede levantar un nuevo issue y veremos de arreglar el mismo lo antes posible.",
        "url": "/iasc-book/"
      }
      ,
    
      "introduccion": {
        "title": "Introduccion",
        "content": "La materia tiene un objetivo doble: por un lado, conocer tecnologías novedosas de aplicación en la industria de desarrollo de software, y por otro lado, transmitir conocimiento durables, ideas que trasciendan la tecnología, sobre la concurrencia, y la arquitectura de software.¿Arquitecturas Concurrentes? ¿Qué es eso?Hace varios años empezamos a armar la materia de Arquitecturas Concurrentes. La razon por la cual empezo esta materia surgia un poco de nuestra frustracion de la poca rigurosidad tecnica que encontramos en el dia a dia en nuestros trabajos frente a problemas de arquitecturas, a veces sobrediseñados, a veces bien ideados aunque muy mal bajados en la implementacion, o en base a lo que esta de moda, sin un solido fundamento. Por otro lado surge de que la concurrencia nos tiene de hijo: no importa cuanto nos esforcemos, los malignos hilos de ejecución lograrán destruir nuestro programa en modos insospechados. El cuidado parece ser siempre insuficiente: de alguna forma irreproducibles bugs de sincronización nos harían morder el suelo.Cual fue la primera impresion una vez que armamos los contenidos iniciales? Que el diablo está en los detalles: muchas ideas de arquitectura y manejo de concurrencia intuitivamente “suenan bien”. Pero recién cuando las bajamos a detalle vemos realmente sus consecuencias.Entonces la materia se trata de dos cosas principales, por un lado dar un estudio bien practico sobre el manejo de la concurrencia, con distintas herramientas. Y por el otro el de dar nociones de arquitecturas distribuidas.A lo largo de la historia de la materia, la idea fue siempre la de adaptar los contenidos con materiales lo mas actualizado posible, y la idea es siempre ir cambiando nuestros temas a lo que consideramos que es abarcar las dos ideas principales antes mencionadas con algunas de las tecnologias mas actuales.Sobre la ArquitecturaPrimero, algunas palabras sobre la arquitectura de software. He aquí algunas interpretaciones comunes y complementarias del término:  Es el diseño lógico de alto nivel: diseñar ya no en términos de componentes como objetos, procedimientos o funciones, sino en términos de módulos, nodos de red, etc  Es el diseño de aquellos aspectos que software que son difíciles de cambiar: tecnologías de base, lenguajes, etc  Es el diseño físico: la selección de los componentes de hardware y el despliegue del software sobre estos componentes. En general no encontramos muchas desavenencias en torno a esta ideas. Los problemas surgen cuando pensamos en cómo hacer arquitectura.Haciendo arquitecturaPara nosotros la construcción de una arquitectura es un proceso:  Iterativo: si bien la arquitectura trata de lidiar con aquellas cosas que son difíciles de cambiar, aún así hay lugar para iterar. Por ejemplo: probablemente cambiar el lenguaje cada 3 iteraciones no sea una opción viable; sin embargo sí lo es empezar con un almacenamiento en archivos o una base embebida SQLite, luego pasar a un motor relacional, luego extraer una parte a una base de datos Mongo, y luego implementar sharding.constructivo: la arquitectura incluye la construcción. Si bien comunicar la arquitectura es una tarea real, la definición de una arquitectura no se limita a generar diagramas de despliegue y listados de tecnologías: hay que meter las manos en el barro. Medir, desplegar, programar, probar, son tareas imprescindibles. Ademas casi es imposible realizar el diseño de una arquitectura con una metodologia en cascada, donde deberiamos ya plantear la arquitectura definitiva en una sola iteracion. Veremos mas adelante que siempre requiren de cambios  verificable: si la arquitectura no se puede validar de forma rápida, entonces el proceso está fallando. De la misma forma que no deberíamos programar todo el sistema antes de hacer las pruebas, o todas las pruebas antes de poner nuestra primera línea de código productivo, o encarar refactors que duren días, tampoco deberíamos embarcarnos en implementar arquitecturas de las que no podamos tener ningún feedback hasta dentro de varios meses.  holístico: en el desarrollo de una arquitectura los aspectos humanos suelen tener mucho más peso que los técnicos o tecnológicos. Así, cuestiones económicas o financieras (debemos reducir el gasto mensual en servidores en X%), políticas (vamos a usar el contenedor de aplicaciones X porque nuestra empresa tiene un convenio con quien lo comercializa), interpersonales (el gerente de sistemas de nuestro sector está peleado con el área de base de datos, por lo que utilizaremos almacenamiento en la nube), entre otras, son aspectos que impactan en el desarrollo. Debemos construir teniendo en cuenta estas cuestiones, que a veces pueden jugarnos en contra, y otras, a favor nuestro.  potenciado por la tecnología: el conocimiento de la tecnología existente nos ayudará a ahorrarnos el esfuerzo de pensar e implementar ideas ya probadas. Sin embargo, las decisiones arquitectónicas no deberán estar guiadas por la tecnología. No se trata de ir al supermercado, dirigirnos a la góndola de tecnologías, comprar una marca particular de una base de datos, un ESB y soporte comercial. Se trata de entender la problemática, pensar soluciones, y utilizar algún producto si realmente calza con lo que necesitamos. Cuando alguien se presente como Arquitecto Java/.Net/Node/LoQueSea, salí corriendo.  enriquecido por la historia: de forma similar al punto anterior, hay valor en conocer las soluciones que otros sistemas aplicaron, pero eso no significa que debamos hacer algo sólo porque otro lo hizo. Debemos siempre entender y estudiar las particularidades de nuestro problema, y no ser naïve pensando que simplemente podemos copiar el éxito de otro ignorando el proceso de meses o años que lo llevó a donde está. Si Facebook hizo X, capaz tu solución no necesite X… ¡porque no sos Facebook! Un punto a tener en cuenta es siempre el de no sobrediseñar nuestra arquitecturaCualidades ArquitectonicasY que consideramos una buena arquitectura? Cuando podemos desarrollar sin problemas ni complejidades, es decir, libre de duplicaciones y que minimicen la redundancia y el codigo que solo es burocracia (en la medida de lo posible), llamado tambien boilerplate, que tengamos buenas abstracciones, que sea facil de mantener y de probar. Y además, como la caracteristica mas importante, que sea simple.La madre de todas las cualidadesPodemos decir que la simplicidad es la madre de todas las cualidades, porque queremos solamente que nuestro sistema deba tener la complejidad mínima necesaria para solucionar una problemática.Everything Should Be Made as Simple as Possible, But Not SimplerCuando la simpleza nos permite desarrollar y mantener un sistema sin mayores problemas, sin perder sus abstracciones escenciales ni duplicando codigo, vamos a poder desarrollar un sistema de manera rapida y el resto de las cualidades serán más fácil de lograrCuidado al escalarSi bien la escalabilidad es algo importante en una gran cantidad de sistemas, y tambien es algo que queremos eventualmente cuando crece nuestro sistema en medida de usuarios o de requerimientos. Pero escalar no es algo gratis, es decir, que generalmente nos puede agregar una complejidad al sistema que no teniamos planeadoDo things that don’t scale.Por eso, siempre es bueno como primera iteracionn de cualquier arquitectura, la que sea mas simple y que soporte la carga de usuarios y recursos que deberiamos soportar a ciencia cierta…  Pero y si no no sabemos cual será la carga, quizás porque es una aplicación que estamos lanzando por primera vez al mercado?Bueno, tal vez a muchos les haga algo de ruido que respondamos a que sea lo mas simple posible, en este caso una aplicación monolitica implementada con las tecnologías que mas rápido les permitan satisfacer sus requerimientos funcionales. Sea Rails o Django, tal vez como primera iteracion da lo misimo.Tengan en cuenta que tambien la decision de la tecnologia depende de que equipo de desarrollo tengan, que experiencia tienen el equipo de desarrollo con el que trabajan y si la tecnología les permite desarrollar sin problemas y que tengan las librerias necesarias para cumplir con los requerimientos funcionales.  Pero…. ¿No soporta miles de transacciones por minuto, no es tolerante a fallos, no puede crecer automáticamente, no puede ser distribuida geográficamente?No se preocupen, tal vez en una primera iteracion no lo necesiten. Además si estan lanzando una aplicacion por primera vez al mercado, tal vez quieran empezar con algo chico y ver si la idea mas alla de todo les resulta. Tambien tengan en cuenta que si queremos además de resolver un problema, que la aplicacion sea toletante a fallos, pueda ser distribuida geográficamente y que pueda crecer automaticamente, tal vez tome mucho mas tiempo, porque no solo es el desarrollo para cumplir con los requerimientos funcionales del trabajo y estos otros requisitos, sino tambien el de hacer pruebas y que todo funcione. Con lo cual esto puede tomar mucho mas tiempo del necesario, para una primera iteracion.Puede suceder que aun asi tienen el presupuesto, el tiempo para cumplir con todo esto; puede suceder el peor de los casos, que es que su aplicacion una vez que esta en el mercado, no lo utilice mucha gente y con lo cual la arquitectura haya quedado sobrediseñada. Esto es un puntapié para dar paso a la proxima sección.YAGNI: You aren’t gonna need itRecién cuando estas necesidades surjan, allí podremos construir en base a requerimientos concretos, medibles. Quizás eso signifique distribuir componentes, introducir redundancias, reescribir parte del código, cambiar la forma en que se despliegan las aplicaciones. Lo mismo vale para otras cualidades duras como la tolerancia a fallos, la carga, la seguridad, etc. Son todas cuestiones que deberemos atacar ante demanda y no tratar de sobrediseñar o pensar muy a largo plazo.Según este enfoque, las buenas arquitecturas no se anticipan, no se planifican. Mas bien, emergen: son la consecuencia de decisiones justificadas en los momentos indicados. Y eso nos lleva a una última idea: las buenas arquitecturas son mínimas.Good design is as little design as possible.Esto es un poco que no hay elementos o componentes innecesarios y si apenas percibimos las restricciones que la arquitectura nos propone, entonces el programar dentro de esa arquitectura se vuelve natural y simple, sin preocuparse mas que en los requerimientos o fallas de un sistema.Entonces, no siempre empezar con microservicios es la mejor alternativa y no solo por el hype deberiamos adoptar una arquitectura o una tecnologia porque esta de moda o porque si…  Moraleja: desconfiá de todo aquel arquitecto que, tras brindarle una somera descripción del problema, te proponga una compleja aplicación distribuida en 12 Capas, 3 lenguajes (Go, Scala, JS, porque están de moda) , un Redis, un Oracle, un Memcached, 4 microservicios, 3 tareas batch, 3 niveles de replicación, un despliegue con Puppet, 10 servidores, un BPM y una lata de duraznos (para asegurar la buena digestión). O cualquier combinación que seguro ya te contaron.Tengan en cuenta que si deciden optar por empezar con una arquitectura mas compleja, de ver los costos y los tiempos que eso conlleva, necesitaran mas tiempo y mas recursos necesariamente, que se traduce en que haya un mayor presupuesto, y si bien llegar a una arquitectura mas compleja puede parecer una buena idea para el futuro. Esta el problema de que tal vez nunca tengan los usuarios o la carga para aprovechar todas las ventajas de su arquitectura propuesta, y ademas, al introducir mayor cantidad de componentes que seguro tiene una arquitectura mas compleja, esto introduce otros problemas que sean de mantenimiento o de errores, con lo cual pued ser incluso contraproducente si despues no pueden solucionar estos en un tiempo que no les afecte al negocio o la idea que propone su sistema.La idea es que su arquitectura no se interponga o complejize el desarrollo de su sistema sea de fallos o nuevos requerimientos, y que ayude a solucionar problemas que son los que estan mas alla de los requerimientos que tiene que resolver un problema, como la carga de usuarios, informacion, distribucion geografica, etc.",
        "url": "/iasc-book/introduccion/"
      }
      ,
    
      "otp": {
        "title": "Capitulo 7 - Actores",
        "content": "Modulos de OTPExisten algunos módulos que fuimos viendo, en mayor o menor medida, o que merecen ser mencionados son:  GenServer  Application  Registry  Agent  Supervisor  Genserver (Genserver Hexdocs)Para una descripcion un poco mas amena de lo que es un Genserver y de lo que hace, junto con ejemplos bastante claros, se puede ver en hexdocs un poco mas de las especificaciones y temas puntuales de genserverUn servidor OTP es un módulo que nos permite modelar un servidor o un cliente en una comunicación de cliente-servidor, y nos va a poder ayudar a que nuestro proceso pueda recibir tanto llamadas sincronicas como asincrónicas por medio de la convención de OTP.En su nivel más básico, un GenServer es un proceso único que ejecuta un bucle que maneja un mensaje por iteración y que siempre devuelve un estado que es el en el que queda el proceso, y también ayuda a modelar, mediante una convención, las distintas respuestas al cliente. También tiene las funciones que nos permiten hacer las llamadas a un servidor Genserver, las llamadas son:  Call: Para realizar llamadas sincrónicas a otro proceso Genserver, que requieren una respuesta del servidor, por medio de un handle_call (Hexdocs)  Cast: Para realizar llamadas asincronicas a otro proceso Genserver, que no necesariamente require una respuesta del servidor, por medio de un handle_cast (Hexdocs)Tenemos tipos de mensajes, tanto asincrónicos como sincronicos, los tipos de mensajes que podemos utilizar son para manejar las llamadas:  Handle_call: Si bien todos los procesos de Elixir el envio de mensajes son asincrónicos, podemos siempre modelar una llamada asincrónica como sincrónica, mediante una espera activa, esperando una respuesta, handle_call nos permite que un proceso Genserver pueda exponer un callback que requiere una respuesta del cliente, por lo que una vez que se procesa este callback, se debe retornar una respuesta o un :reply que está conformado por la tupla {:reply, response, state}. Podemos ver todas la opciones de lo que puede retornar un handle_call (Hexdocs)  Handle_cast: Permite manejar mensajes asincronicos mediate llamadas cast, y que pueden devolver un resultado o no necesariamente. (Hexdocs)  Handle_info: Permite manejar cualquier otro tipo de mensajes (Hexdocs))Application (Hexdocs)Este modulo permite modelar procesos que sirvan como un punto de entrada a nuestra aplicacion, sea para inicializar una aplicacion Erlang o de OTP, se puede ver un poco mas de detalle de este modulo en hexdocsRegistry (Hexdocs)Son un módulo de OTP que nos permite modelar procesos que nos permiten almacenar valores clave/valor de manera descentralizada. Suelen ser usados para algunas cosas como:  Dispatching  Registro de claves clave/valor  Registro de claves pub/subDespués hay una manera de tener un sotre pero a lo largo de la instancia llamado ETS (Hexdocs)Si se quiere tener un proceso que guarde un estado que no sea necesariamente algo del estilo clave/valor, podemos optar por otro tipo de módulo llamado AgentAgent (Hexdocs)El agent es un módulo que nos permite modelar un proceso que permita almacenar un estado, y en general se usa solo para este propósito, obviamente este almacenamiento, tanto los Agent como los Registry, es solo en memoria y no se persiste en disco. Pueden ver el link en el titulo para mayor información, algo interesante para ver es la sección de cómo supervisar un Agent (https://hexdocs.pm/elixir/Agent.html#module-how-to-supervise).Supervisores (Hexdocs)Un supervisor es un proceso que supervisa otros procesos, a los que nos referimos como procesos secundarios. Los supervisores se utilizan para construir una estructura de proceso jerárquica denominada árbol de supervisión. Los árboles de supervisión proporcionan tolerancia a fallos y resumen cómo se inician y se cierran nuestras aplicaciones. Por lo que podemos reiniciar una lista de procesos por medio de un supervisor en caso de que alguno de esos procesos se caiga, sea por un error o no..Se tiene que tener varias cosas en cuentas sobre un esquema de supervisión…La especificación de los hijos o procesos que serán especificadosDocumentacion de la especificacionDos de los argumentos de las especificaciones del child spec son:el valor de shutdown, que es la estrategia de cómo se debería cerrar o matar el proceso, cuando falla o se cae.Y más importante es la del valor de reinicio de un proceso supervisadoComo se define un Supervisor?Mediante un modulo generalmente (Hexdocs)Ahora el supervisor recibe además de un child_spec una estrategia de supervisión, que será la acción que tomará un supervisor cuando se caen los procesos supervisados.En el child spec siempre vamos no solo a poder supervisar procesos que son hojas, o sea procesos que van a tener lógica de un sistema, o de nuestra aplicación, o pueden ser otros nodos que pueden ser no terminales, o sea, supervisores, por lo que podemos armar un árbol de supervisión de esta manera.Hay otras estrategias deprecadas, tales como las :simple_one_for_one, que hoy fueron reemplazadas por otro tipo de supervisores, esto es porque los Supervisor son para modelar procesos que son supervisores estáticos, o sea que una vez inicializado no se pueden agregar procesos supervisados, por lo que al ser estático, si se quieren hacer cambios, se debe cambiar el childspec, levantar de nuevo la aplicación y volver a inicializar el supervisor.El otro tipo de supervisores que hoy existe en Elixir y que nos permite inicializar dinámicamente procesos supervisados son los Supervisores dinámicosEsta es la documentación de los hexdocs con algunos puntos bien puntuales sobre los detalles de los supervisores dinamicosEsta es la documentación un poco más descriptiva de los supervisores dinamicosRecuerden bien que un supervisor no restaura ni guarda el estado del actor supervisado, una vez que muere, si este es reiniciado, vuelve a ser inicializado con el estado inicial, y si tenía un estado distinto antes de su muerte, este se pierde definitivamente, por lo que a veces es bueno tal vez o bien persistirlo o si es algo importante tenerlo en otro actor como puede ser un Agent.Otros recursos, tal vez un poco desactualizados:Manejo de Errores e Introducción a la supervisión",
        "url": "/iasc-book/otp/"
      }
      ,
    
      "search": {
        "title": "Busqueda dentro del sitio",
        "content": "  Ingresa alguna palabra clave        Search Results    ",
        "url": "/iasc-book/search/"
      }
      ,
    
      "stm": {
        "title": "STM",
        "content": "{% remote_markdown https://raw.githubusercontent.com/arquitecturas-concurrentes/iasc-stm-haskell-2019/master/01_semaphores_and_philosophers/README.md %}",
        "url": "/iasc-book/stm/"
      }
      ,
    
      "css-style-css": {
        "title": "",
        "content": "body {    font-family: 'Poppins', sans-serif;    background: #fafafa;}p {    font-family: 'Poppins', sans-serif;    font-size: 1.1em;    font-weight: 300;    line-height: 1.7em;    color: #999;}a, a:hover, a:focus {    color: inherit;    text-decoration: none;    transition: all 0.3s;}.navbar {    padding: 15px 10px;    background: #fff;    border: none;    border-radius: 0;    margin-bottom: 2px;    box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);}.navbar-btn {    box-shadow: none;    border: none;}.line {    width: 100%;    height: 1px;    border-bottom: 1px dashed #ddd;    margin: 40px 0;}.title {    text-align: center;}/* ---------------------------------------------------    SIDEBAR STYLE----------------------------------------------------- */.wrapper {    display: flex;    width: 100%;    align-items: stretch;    overflow: hidden;    min-height: 650px;}.sidebar {    min-width: 250px;    max-width: 250px;    background: #6B7A8F;    color: #fff;    transition: all 0.6s cubic-bezier(0.945, 0.020, 0.270, 0.665);    transform-origin: bottom left;}.sidebar-inactive {    margin-left: -250px;    transform: rotateY(100deg);}.sidebar .sidebar-header {    padding: 20px;    background: #6B7A8F;}.sidebar .components {    padding: 20px 0;    border-bottom: 1px solid #6B7A8F;}.sidebar ul p {    color: #fff;    padding: 10px;}.sidebar ul li a {    padding: 10px;    font-size: 1.1em;    display: block;}.sidebar ul li a:hover {    color: #7187a7;    background: #fff;}.sidebar ul li.active > a, a[aria-expanded=\"true\"] {    color: #fff;    background: #7187a7;}a[data-toggle=\"collapse\"] {    position: relative;}.dropdown-toggle::after {    display: block;    position: absolute;    top: 50%;    right: 20px;    transform: translateY(-50%);}ul ul a {    font-size: 0.9em;    padding-left: 30px;    background: #6B7A8F;}.navbar-button, .navbar-button:hover {    background: #F7882F;    color: #fff;}/* ---------------------------------------------------    CONTENT STYLE----------------------------------------------------- */.content {    width: 100%;    padding: 20px;    min-height: 100vh;    transition: all 0.3s;}.sidebarCollapse {    position:fixed;    bottom:40px;    right:40px;    width: 40px;    height: 40px;    background: #f5f5f5;    cursor: pointer;    border-radius:50px;    text-align:center;    box-shadow: 2px 2px 3px #999;}.sidebarCollapse span {    width: 80%;    height: 2px;    margin: 0 auto;    display: block;    background: #555;    transition: all 0.8s cubic-bezier(0.810, -0.330, 0.345, 1.375);    transition-delay: 0.2s;}.sidebarCollapse span:first-of-type {    transform: rotate(45deg) translate(2px, 2px);}.sidebarCollapse span:nth-of-type(2) {    opacity: 0;}.sidebarCollapse span:last-of-type {    transform: rotate(-45deg) translate(1px, -1px);}.sidebarCollapse.active span {    transform: none;    opacity: 1;    margin: 5px auto;}.inner-content {    margin-bottom: 50px;    padding-top: 25px;    font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;    font-size: 20px;    color: #333333;}.inner-content p {    font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;    font-size: 20px;    color: #404040;}.inner-content a {    color: #F7882F;}.inner-content a:hover {    color: #6B7A8F;}.container-background {    background-image: url(\"{{site.relative_url}}/img/home-bg.jpg\");    min-height: 150px;}.titulo-heading {    margin-bottom: 15px;}.titulo {    padding-top: 10px;    padding-bottom: 10px;    padding-left: 40px;    font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;    color: #FFFFFF;    text-shadow: 1px 1px 4px rgba(0,0,0,0.5);}.center {    display: block;    margin-left: auto;    margin-right: auto;}.footer {    height: 2em;    bottom: 0;    color: #aaa;    width: 100%;    background-color: #333333;    font-size: 0.9rem;}.search-results {    margin-top: 70px;    margin-bottom: 50px;}.search-leftbar {    max-width: 100%;    overflow: visible;}.header {    padding-left: 0px;    padding-right: 0px;}/* ---------------------------------------------------    MEDIAQUERIES----------------------------------------------------- */@media (max-width: 768px) {    .sidebar-inactive {        margin-left: -170px;        transform: rotateY(90deg);    }    .sidebar {        min-width: 40%;        max-width: 40%;    }}",
        "url": "/iasc-book/css/style.css"
      }
      
    
  };
</script>


</div>
            </div>
        </div>
    </div>
</div>


<div class="footer">
    <div class="columns small-12 medium-12 large-12">
        © 2020 - IASC
    </div>
</div>
<!-- jQuery CDN - Slim version (=without AJAX) -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
<!-- Popper.JS -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js"
        integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ"
        crossorigin="anonymous"></script>
<!-- Bootstrap JS -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js"
        integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm"
        crossorigin="anonymous"></script>
<!-- Lunr JS Search -->
<!-- <script src="https://unpkg.com/lunr/lunr.js"></script> -->
<script src="https://unpkg.com/lunr@1.0/lunr.js"></script>
<script src="/iasc-book//js/search.js"></script>


<!--This part will enable the circle button to show/hide the right bar-->
<script type="text/javascript">
    $(document).ready(function () {
        $('#sidebarCollapse').on('click', function () {
            $('.sidebar').toggleClass('sidebar-inactive');
            $(this).toggleClass('active');
        });
    });
</script>


</body>

</html>
